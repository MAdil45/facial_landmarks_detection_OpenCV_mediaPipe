{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9167d15e-6a09-46d9-a866-26ad00157e08",
   "metadata": {},
   "source": [
    "# Facial Landmark Detection Using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100f805-8cc4-4636-9503-2ab88451e523",
   "metadata": {},
   "source": [
    "Here, we will be using OpenCV and Mediapip library for real-time facial landmarks detection. We will be detecting 468 facial landmarks. The facial landmark detection is often used in augmented reality applications. For example, there exist filters to put masks, glasses, objects on your face, those application greatly assisted from facial landmark detection.\n",
    "\n",
    "Mediapipe is designed to use time series data, like video, audio for customizeable ML applications. Few applications include - iris detections to detect eyes, hand detection to detect all fingers,posture detection to detect the pose of the person,and Holistic detection, which utilizes the pose, face and hand landmark models to generate a total of 543 landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9a2d9-5cd6-4766-872f-8a641b3c90ff",
   "metadata": {},
   "source": [
    "importing the required libraries: cv2 and mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a924a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c20d556-4f44-49c9-8b6d-6b6eda3f2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "my_drawing_spec = mp_drawing.DrawingSpec(color=(0,255,0), thickness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34231570-cce7-4987-bf52-53b788a9b1d0",
   "metadata": {},
   "source": [
    "Lets setup a simple setup to read the webcame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe05a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# showing the webcam \n",
    "while cap.isOpened:\n",
    "    \n",
    "    # here success will decide the duration of the loop, as soon as it gets to\n",
    "    # false, the loop will break.\n",
    "    succes, img = cap.read()\n",
    "    if not succes:\n",
    "        break\n",
    "    \n",
    "    # lets show the img being read above\n",
    "    cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c5e61-6f9c-4305-9d3e-14348f95ff3a",
   "metadata": {},
   "source": [
    "Lets utilize the mediapipe library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571eb56-d827-4096-af2a-62e68ff64352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# calling the mediapipe library - first we will be calling mp.solutions\n",
    "# afterward, we will be using face_mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# lets use the FaceMesh from above my_face_mesh\n",
    "# this FaceMesh take couple of arguments - first max_num_faces, which will be\n",
    "# the maximum number of faces - here I am going to set it 1.\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.2,\n",
    "    min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "    # now to use the above api -  we have to read the video inside this loop\n",
    "\n",
    "    # showing the webcam \n",
    "    while cap.isOpened:\n",
    "\n",
    "        # here success will decide the duration of the loop, as soon as it gets to\n",
    "        # false, the loop will break.\n",
    "        succes, img = cap.read()\n",
    "        if not succes:\n",
    "            break\n",
    "        # we have ready the image, just pass that image to the api\n",
    "        results = face_mesh.process(img)\n",
    "        \n",
    "        # inside this results, we will have list of landmarks coordinates\n",
    "        # containing x, y, z coordinates\n",
    "        # now lets draw those landmarks - we will be using drawing utils from \n",
    "        # mediapipe - i have already imported them earlier\n",
    "        # i have also imported drawing styles with which we will also be playing\n",
    "        \n",
    "        # lets loop through results facial landamarks and use draw_landmarks\n",
    "        # from mp_drawing to draw the landmarks. \n",
    "        # it will take a numpy image, landmarks list, connections to specify\n",
    "        # what kind of style we want to draw\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image = img, \n",
    "                                      landmark_list=facial_landmarks,\n",
    "                                      connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                      landmark_drawing_spec= None,\n",
    "                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()                                \n",
    "                                     )\n",
    "    \n",
    "        # lets show the img being read above\n",
    "        cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6f00e-e75d-4b74-951e-ecd3a21f9055",
   "metadata": {},
   "source": [
    "Lets draw a outlines at different facial features - like nose, lips, eyes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8406789-771a-41c1-aa9d-2a4b3abd3bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 40\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# inside this results, we will have list of landmarks coordinates\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# containing x, y, z coordinates\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# now lets draw those landmarks - we will be using drawing utils from \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# it will take a numpy image, landmarks list, connections to specify\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# what kind of style we want to draw\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m facial_landmarks \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_face_landmarks:\n\u001b[0;32m     41\u001b[0m     mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(image \u001b[38;5;241m=\u001b[39m img, \n\u001b[0;32m     42\u001b[0m                               landmark_list\u001b[38;5;241m=\u001b[39mfacial_landmarks,\n\u001b[0;32m     43\u001b[0m                               connections\u001b[38;5;241m=\u001b[39mmp_face_mesh\u001b[38;5;241m.\u001b[39mFACEMESH_CONTOURS,\n\u001b[0;32m     44\u001b[0m                               landmark_drawing_spec\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     45\u001b[0m                               connection_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing_styles\u001b[38;5;241m.\u001b[39mget_default_face_mesh_contours_style()                                \n\u001b[0;32m     46\u001b[0m                              )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# lets show the img being read above\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# calling the mediapipe library - first we will be calling mp.solutions\n",
    "# afterward, we will be using face_mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# lets use the FaceMesh from above my_face_mesh\n",
    "# this FaceMesh take couple of arguments - first max_num_faces, which will be\n",
    "# the maximum number of faces - here I am going to set it 1.\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.2,\n",
    "    min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "    # now to use the above api -  we have to read the video inside this loop\n",
    "\n",
    "    # showing the webcam \n",
    "    while cap.isOpened:\n",
    "\n",
    "        # here success will decide the duration of the loop, as soon as it gets to\n",
    "        # false, the loop will break.\n",
    "        succes, img = cap.read()\n",
    "        if not succes:\n",
    "            break\n",
    "        # we have ready the image, just pass that image to the api\n",
    "        results = face_mesh.process(img)\n",
    "        if results is None: continue\n",
    "        \n",
    "        # inside this results, we will have list of landmarks coordinates\n",
    "        # containing x, y, z coordinates\n",
    "        # now lets draw those landmarks - we will be using drawing utils from \n",
    "        # mediapipe - i have already imported them earlier\n",
    "        # i have also imported drawing styles with which we will also be playing\n",
    "        \n",
    "        # lets loop through results facial landamarks and use draw_landmarks\n",
    "        # from mp_drawing to draw the landmarks. \n",
    "        # it will take a numpy image, landmarks list, connections to specify\n",
    "        # what kind of style we want to draw\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image = img, \n",
    "                                      landmark_list=facial_landmarks,\n",
    "                                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                      landmark_drawing_spec= None,\n",
    "                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()                                \n",
    "                                     )\n",
    "    \n",
    "        # lets show the img being read above\n",
    "        cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c6c7c-b4e0-492e-ad5f-5a9997b5e442",
   "metadata": {},
   "source": [
    "lets specify our own colors and style - we just need to replace the mp_drawing_styles with the variable I created above - my_drawing_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f47d864-7b1a-4946-b496-73e5444c7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# calling the mediapipe library - first we will be calling mp.solutions\n",
    "# afterward, we will be using face_mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# lets use the FaceMesh from above my_face_mesh\n",
    "# this FaceMesh take couple of arguments - first max_num_faces, which will be\n",
    "# the maximum number of faces - here I am going to set it 1.\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.2,\n",
    "    min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "    # now to use the above api -  we have to read the video inside this loop\n",
    "\n",
    "    # showing the webcam \n",
    "    while cap.isOpened:\n",
    "\n",
    "        # here success will decide the duration of the loop, as soon as it gets to\n",
    "        # false, the loop will break.\n",
    "        succes, img = cap.read()\n",
    "        if not succes:\n",
    "            break\n",
    "        # we have ready the image, just pass that image to the api\n",
    "        results = face_mesh.process(img)\n",
    "        \n",
    "        # inside this results, we will have list of landmarks coordinates\n",
    "        # containing x, y, z coordinates\n",
    "        # now lets draw those landmarks - we will be using drawing utils from \n",
    "        # mediapipe - i have already imported them earlier\n",
    "        # i have also imported drawing styles with which we will also be playing\n",
    "        \n",
    "        # lets loop through results facial landamarks and use draw_landmarks\n",
    "        # from mp_drawing to draw the landmarks. \n",
    "        # it will take a numpy image, landmarks list, connections to specify\n",
    "        # what kind of style we want to draw\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image = img, \n",
    "                                      landmark_list=facial_landmarks,\n",
    "                                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                      landmark_drawing_spec= None,\n",
    "                                      connection_drawing_spec=my_drawing_spec\n",
    "                                      # .get_default_face_mesh_contours_style()                                \n",
    "                                     )\n",
    "    \n",
    "        # lets show the img being read above\n",
    "        cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f97d43-f541-40d0-9653-033f8ec3248a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
