{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9167d15e-6a09-46d9-a866-26ad00157e08",
   "metadata": {},
   "source": [
    "# Facial Landmark Detection Using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100f805-8cc4-4636-9503-2ab88451e523",
   "metadata": {},
   "source": [
    "Here, we will be using OpenCV and Mediapip library for real-time facial landmarks detection. We will be detecting 468 facial landmarks. The facial landmark detection is often used in augmented reality applications. For example, there exist filters to put masks, glasses, objects on your face, those application greatly assisted from facial landmark detection.\n",
    "\n",
    "Mediapipe is designed to use time series data, like video, audio for customizeable ML applications. Few applications include - iris detections to detect eyes, hand detection to detect all fingers,posture detection to detect the pose of the person,and Holistic detection, which utilizes the pose, face and hand landmark models to generate a total of 543 landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9a2d9-5cd6-4766-872f-8a641b3c90ff",
   "metadata": {},
   "source": [
    "importing the required libraries: cv2 and mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a924a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c20d556-4f44-49c9-8b6d-6b6eda3f2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "my_drawing_spec = mp_drawing.DrawingSpec(color=(0,255,0), thickness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34231570-cce7-4987-bf52-53b788a9b1d0",
   "metadata": {},
   "source": [
    "Lets setup a simple setup to read the webcame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe05a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# showing the webcam \n",
    "while cap.isOpened:\n",
    "    \n",
    "    # here success will decide the duration of the loop, as soon as it gets to\n",
    "    # false, the loop will break.\n",
    "    succes, img = cap.read()\n",
    "    if not succes:\n",
    "        break\n",
    "    \n",
    "    # lets show the img being read above\n",
    "    cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c5e61-6f9c-4305-9d3e-14348f95ff3a",
   "metadata": {},
   "source": [
    "Lets utilize the mediapipe library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b571eb56-d827-4096-af2a-62e68ff64352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# calling the mediapipe library - first we will be calling mp.solutions\n",
    "# afterward, we will be using face_mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# lets use the FaceMesh from above my_face_mesh\n",
    "# this FaceMesh take couple of arguments - first max_num_faces, which will be\n",
    "# the maximum number of faces - here I am going to set it 1.\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.2,\n",
    "    min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "    # now to use the above api -  we have to read the video inside this loop\n",
    "\n",
    "    # showing the webcam \n",
    "    while cap.isOpened:\n",
    "\n",
    "        # here success will decide the duration of the loop, as soon as it gets to\n",
    "        # false, the loop will break.\n",
    "        succes, img = cap.read()\n",
    "        if not succes:\n",
    "            break\n",
    "        # we have ready the image, just pass that image to the api\n",
    "        results = face_mesh.process(img)\n",
    "        \n",
    "        # inside this results, we will have list of landmarks coordinates\n",
    "        # containing x, y, z coordinates\n",
    "        # now lets draw those landmarks - we will be using drawing utils from \n",
    "        # mediapipe - i have already imported them earlier\n",
    "        # i have also imported drawing styles with which we will also be playing\n",
    "        \n",
    "        # lets loop through results facial landamarks and use draw_landmarks\n",
    "        # from mp_drawing to draw the landmarks. \n",
    "        # it will take a numpy image, landmarks list, connections to specify\n",
    "        # what kind of style we want to draw\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image = img, \n",
    "                                      landmark_list=facial_landmarks,\n",
    "                                      connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                      landmark_drawing_spec= None,\n",
    "                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()                                \n",
    "                                     )\n",
    "    \n",
    "        # lets show the img being read above\n",
    "        cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6f00e-e75d-4b74-951e-ecd3a21f9055",
   "metadata": {},
   "source": [
    "Lets draw a outlines at different facial features - like nose, lips, eyes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8406789-771a-41c1-aa9d-2a4b3abd3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# calling the mediapipe library - first we will be calling mp.solutions\n",
    "# afterward, we will be using face_mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# lets use the FaceMesh from above my_face_mesh\n",
    "# this FaceMesh take couple of arguments - first max_num_faces, which will be\n",
    "# the maximum number of faces - here I am going to set it 1.\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.2,\n",
    "    min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "    # now to use the above api -  we have to read the video inside this loop\n",
    "\n",
    "    # showing the webcam \n",
    "    while cap.isOpened:\n",
    "\n",
    "        # here success will decide the duration of the loop, as soon as it gets to\n",
    "        # false, the loop will break.\n",
    "        succes, img = cap.read()\n",
    "        if not succes:\n",
    "            break\n",
    "        # we have ready the image, just pass that image to the api\n",
    "        results = face_mesh.process(img)\n",
    "        if results is None: continue\n",
    "        \n",
    "        # inside this results, we will have list of landmarks coordinates\n",
    "        # containing x, y, z coordinates\n",
    "        # now lets draw those landmarks - we will be using drawing utils from \n",
    "        # mediapipe - i have already imported them earlier\n",
    "        # i have also imported drawing styles with which we will also be playing\n",
    "        \n",
    "        # lets loop through results facial landamarks and use draw_landmarks\n",
    "        # from mp_drawing to draw the landmarks. \n",
    "        # it will take a numpy image, landmarks list, connections to specify\n",
    "        # what kind of style we want to draw\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image = img, \n",
    "                                      landmark_list=facial_landmarks,\n",
    "                                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                      landmark_drawing_spec= None,\n",
    "                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()                                \n",
    "                                     )\n",
    "    \n",
    "        # lets show the img being read above\n",
    "        cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c6c7c-b4e0-492e-ad5f-5a9997b5e442",
   "metadata": {},
   "source": [
    "lets specify our own colors and style - we just need to replace the mp_drawing_styles with the variable I created above - my_drawing_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f47d864-7b1a-4946-b496-73e5444c7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# calling the mediapipe library - first we will be calling mp.solutions\n",
    "# afterward, we will be using face_mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# lets use the FaceMesh from above my_face_mesh\n",
    "# this FaceMesh take couple of arguments - first max_num_faces, which will be\n",
    "# the maximum number of faces - here I am going to set it 1.\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.2,\n",
    "    min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "    # now to use the above api -  we have to read the video inside this loop\n",
    "\n",
    "    # showing the webcam \n",
    "    while cap.isOpened:\n",
    "\n",
    "        # here success will decide the duration of the loop, as soon as it gets to\n",
    "        # false, the loop will break.\n",
    "        succes, img = cap.read()\n",
    "        if not succes:\n",
    "            break\n",
    "        # we have ready the image, just pass that image to the api\n",
    "        results = face_mesh.process(img)\n",
    "        \n",
    "        # inside this results, we will have list of landmarks coordinates\n",
    "        # containing x, y, z coordinates\n",
    "        # now lets draw those landmarks - we will be using drawing utils from \n",
    "        # mediapipe - i have already imported them earlier\n",
    "        # i have also imported drawing styles with which we will also be playing\n",
    "        \n",
    "        # lets loop through results facial landamarks and use draw_landmarks\n",
    "        # from mp_drawing to draw the landmarks. \n",
    "        # it will take a numpy image, landmarks list, connections to specify\n",
    "        # what kind of style we want to draw\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image = img, \n",
    "                                      landmark_list=facial_landmarks,\n",
    "                                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                      landmark_drawing_spec= None,\n",
    "                                      connection_drawing_spec=my_drawing_spec\n",
    "                                      # .get_default_face_mesh_contours_style()                                \n",
    "                                     )\n",
    "    \n",
    "        # lets show the img being read above\n",
    "        cv.imshow('Video is being shown', cv.flip(img, 1))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF ==ord ('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f97d43-f541-40d0-9653-033f8ec3248a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
